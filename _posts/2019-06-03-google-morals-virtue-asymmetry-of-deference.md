---
layout: post
title: "Okay Google, should I punch my friend?"
date: 2019-06-03
excerpt_separator: <!--cut-->
---
## The Short Version
Forming beliefs on moral issues by deferring to someone or something else is problematic because these beliefs don't integrate with our moral character. These beliefs are *isolated* from our moral character because they don't hook into our moral values or reasoning.

<!--cut-->

## The Puzzle
{: id="anchor"}
Imagine that Google has just released their latest app entitled Google Morals. Just like how you can ask Google how to get somewhere, now with Google Morals you can ask what to do for any moral issue. Should I eat this steak? Should I be an organ donor? Google Morals will answer any of these questions with a simple "Yes" or "No."

To me, immediately it seems like there's something off about using Google Morals. It doesn't seem right to entrust our own moral issues to something that purports to be a moral expert. I do defer to Google on other things like the radius of the Earth or how to get to the airport, but something seems different with moral issues.

Robert J. Howell provides a novel account of what exactly is especially wrong about deferring on moral issues that isn't a problem for deferring on non-moral issues.[^Howell_paper] We'll get to this in a minute, but Howell thinks it has to do with how deferring affects our moral character.

[^Howell_paper]: "Google Morals, Virtue, and the Asymmetry of Deference," *Nous* 48:3 (2014):p.389-415

## The Definition of Moral Deference

A significant part of the paper is devoted to talking about what exactly moral deference is and its many types. Some of it is technical so I leave it out to make my job easier. Howell thinks that deference includes (i) **forming a belief in p** (p is some statement like "Mercury is the closest planet to the Sun") based on another person's believing p and (ii) **sustaining that belief in p based on another person's believing p**. So we're not using whatever definition of deference that's in the dictionary (though that's a good starting point).

Why should we use Howell's definition of deference? Howell thinks that this definition covers at least the essential aspects of deference; we believe and continue to believe p because someone told us so.

For example, I might not know what the closest planet to the Sun is, but I know my friend who's really into Astronomy does know (or should know). I ask my friend, and she tells me it's Mercury. That's p, the statement that Mercury is the closest planet to the Sun. Now, I believe p because my friend told me so. I haven't actually looked it up on Wikipedia or seen it for myself so I'm believing p based on what my friend believes.[^no_lies]

[^no_lies]: I'm assuming here that my friend telling me p also means that she believes p. I don't think she would lie to me about this.

The next day someone asks me what the closest planet to the Sun is (it's some new trend I guess). I tell them it's Mercury, and when they ask me how I know that I tell them my friend who's really into Astronomy told me. This is (ii) of Howell's definition. I continue to believe that Mercury is the closest planet to the Sun based on what my friend told me. I haven't seen for myself that Mercury is the closest planet to the Sun.

**This is important!** Howell's definition means that I believe and will continue to believe that Mercury is the closest planet to the Sun solely because my friend told me.[^sustain_how_long] Deferring to my friend on this fact means that I don't see for myself why Mercury is the closest planet to the Sun. You might think this is problematic, but Howell thinks the bigger problem is with deferring on moral issues.

[^sustain_how_long]: Howell seems to mean that deferring on p means that we sustain our belief in p forever based on someone else's word, but he also doesn't seem to mean this which confuses me. See his discussion at the end of the paper on moral development for this.

For example, I'm discussing with my friend over the phone whether I should register as an organ donor, and I just can't reach a conclusion. After I hang up, I ask Google Morals whether I should register as an organ donor. Let's assume Google Morals says that I should register as an organ donor. So now I believe I should register as an organ donor because Google Morals told me so.

Already, this might seem off to you, but wait it gets worse! The next day my friend asks me what I ended up doing, and I tell him I registered as an organ donor. He asks me why, and I tell him because Google Morals told me so. Wait, what! This seems very wrong. You might think (like me) that deferring to your friend on whether Mercury is the closest planet to the Sun is okay at best, but deferring to Google Morals on whether I should be an organ donor seems worse if not just outright bad. If your intuition doesn't line up with mine, Howell's account gives some reasons to think moral deference is especially bad.

## What's wrong with moral deference?

Howell offers several possible accounts of why moral deference is bad and worse than non-moral deference, but he thinks that only his account gives the full story of what's at the heart of the problem.

I won't go through all of the possible accounts, but here are at least the ones I thought touched on an important aspect of the problem.

### Understanding
If you think about it, Google Morals only tells you what you should do and nothing more. It doesn't tell you why you should do it or what sort of reasoning led to its conclusion. I might know correctly (at best) that I should register as an organ donor, but what's wrong is that I don't understand why I should register as an organ donor. The *why* includes the benefits of donating my organs and my right to what happens to my body. If I don't understand why I should register as an organ donor, how would I know what to do in a similar case? Would I always ask Google Morals what to do? This seems to explain what's wrong with asking Google Morals what to do.

<!-- Google rolls out a new feature for Google Morals that now also tells you why you should do what it tells you to do. (Howell's argument for the lack of distinction between understanding why and knowing why)

But I don't think you're really understanding why even if you know why. You also need to internalize the why to really understand why. -->

Howell argues that this understanding account only partially explains what's wrong with moral deference. There are cases where we understand why we should do what Google Morals tells us to do, but it still seems problematic. For example, we may defer to Google Morals on which moral theory is right, and if it says utilitarianism is right we would understand the reason behind whatever Google Morals tells us to do. For example, we might know why Google Morals says we should be vegetarians (because it would minimize the suffering of animals), but we still wouldn't know why utilitarianism is correct.

<!-- He uses the examples of Sam, Urkel, Alastair, and Ursula to show this.

Sam understands all the moral theories: utilitarianism, deontology, etc. However, like most of us, he doesn't know which moral theory is the right one. So he asks Google Morals which one is the right one, and let's say Google Morals says it's utilitarianism. Now, whenever Sam is faced with some moral dilemma, he knows what to do since he understands how to apply utilitarianism.

Here, Sam understands why he needs to do some action, but something still seems wrong. This takes care of the problem the understanding account brings up. Sam understands, for example, why he should register as an organ donor. But he doesn't understand why utilitarianism is the correct moral theory. Howell doesn't address this worry so I'm still not convinced that the understanding account is only a partial explanation.

Urkel is unlike us. He defers to Google Morals on what to do, but he can justify whatever Google's answer is. In this way, he understands why, but there is something seriously wrong with Urkel. He defers even on the 'simplest' questions like "Is it wrong to torture babies?" He doesn't have the basic moral intuitions that we all have when confronted with a moral question.

Howell wants to show us that though Sam and Urkel have understanding they still have serious problems so the understanding account cannot give us the full story. I don't actually think this is right because Howell seems to have given us cases of partial understanding.

Alastair is admirable. He doesn't defer to Google Morals and has the intuitions and arguments to back up his moral beliefs. However, he is always wrong. Because we cannot understand something that is false, Howell thinks that Alastair lacks understanding but still has some positive features.

Ursula doesn't have understanding (in any way really). She defers to Google Morals, but nearly all the time she acts morally even without Google's help.

These last two cases are supposed to show us that though Alastair and Ursula don't have understanding they still have some positive attributes.

The point with these four cases is that understanding doesn't give a full story of the problem with moral deference because problems are left unaccounted for and positives are left unaccounted by understanding. -->

### Because you told me so...
Another account Howell considers is that the problem with moral deference is that we are acting some way because someone else told us to do so.

Howell thinks we are skipping a step here. We act some way because we believe it is the right thing to do. We believe it is the right thing to do because someone else (who we think is reliable) told us. Learning from testimony is not always bad, and we act from the belief we gain from testimony.

### It's your job!
The final account Howell mentions (there are so many!) is about doing our job.

Consider Gary the Googler. Gary doesn't trust himself to do the right thing so whenever something comes up he asks Google Morals what to do.

We might have two responses to what Gary is doing. On one hand, something seems off about what Gary is doing. Howell thinks it has to do with how we think it's everyone's job to figure out what to do (morally speaking). On the other hand, we also might think Gary is being responsible. He understands that he is not a moral expert so he defers to one.

To better understand this second response, consider Patty the physicist. It is Patty's job to advance our knowledge of physics. But it is not my job to do physics research. Then, it seems responsible of me to defer to Patty about facts of physics or things in her expertise. After all, I'm not the expert. This seems to be exactly what Gary is doing but for moral truths.

Howell thinks that this account doesn't really explain anything since now we're left with the question of why *we* are responsible for figuring out moral truths and why we are not responsible for figuring out non-moral truths. We're just posing another question in response to the first question of why moral deference is worse than non-moral deference.[^still_interesting]

[^still_interesting]: I actually think this would be interesting to think about! In fact, I'm not quite convinced by Howell's objection here because it does seem like certain asymmetries may be deeper than others. How do we know the asymmetry of deference is not merely a symptom of this new asymmetry?

## Howell's account
So now that we've considered a list of (supposedly) problematic accounts, let's take a look at Howell's.

In one sentence, Howell thinks the problem with moral deference is that it indicates a lack of moral virtue or makes it harder to acquire moral virtue. In Howell's own words, "the beliefs sustained by deference are largely isolated from the moral character of the agent" (p.402). There's a lot squeezed into that sentence so let's unpack it.

First, moral character is used in much the same way that we talk about someone's character. Moral character has to do with what kinds of virtues we have.

"To have a virtue is to have a reliable disposition to act and feel in certain ways" (p.403). For example, if I have the virtue of courage, then I (nearly all the time) am able to act and feel courageously. If this seems circular, that's good to keep in mind. I want to focus more on what it means to have virtue; let's assume we know what courage is and what a courageous action is.

The core of Howell's account is that by deferring we don't properly integrate these "virtuous features" (the disposition, acting, feelings) with our moral character. This means we only get the corresponding moral belief and none of the corresponding virtuous features such as the feelings or disposition. Then,
we either lack the relevant virtue and/or it makes it harder to acquire that virtue in the future (p.403).

For example, I'm walking down the street and I see a homeless man. If I have the virtue of compassion or generosity, I might try to help this man with food, shelter, or money. But it's not just the action. As I give this man some money, I will feel relieved or glad that I'm helping this man. It's also the case that I would almost always do the same thing in a similar situation. This is what it takes to have the virtue. Just the action is not enough.

Now compare this to an alternate situation. I'm walking down the street and I see a homeless man. Not sure about whether I should just pass by or try to help, I ask Google Morals what to do. Google Morals tells me I should help this man. So I also give this man some money like before. But this time I feel torn about giving money. I was going to use that to buy ice cream so I feel frustrated ("What a jerk!" we might think). In a similar situation, I might try to ignore the man since I know what Google Morals will tell me. In this case, I do not have the virtue of compassion or generosity. I don't/can't feel the right feelings or consistenly act compassionately. Since I **only** act correctly, I don't satisfy all the conditions to integrate the relevant virtue with my moral character.

But moral deference can also make it harder to acquire moral virtue. This is where Howell defers to the understanding account.[^joke] We don't understand the reasons for the belief we get from moral deference so we can't apply it to similar situations we get into. I might learn from Google Morals that I should give money to the homeless man, but if I don't understand why Google Morals told me this I most likely will not do the same in similar, future encounters. This means that acquiring the virtue of compassion or generosity will be more difficult because I can't consistently apply the knowledge I get from moral deference.

[^joke]: I had to do it.

So that's it! I think Howell's virtue account is very insightful, but there's definitely more to be said on this.
